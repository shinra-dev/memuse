\section{Other}

\subsection{Comparison to \code{object.size()}}

\proglang{R} contains a handy tool for telling you how big an already allocated object is, the \code{object.size()} function.  The functions in this package are essentially an extension of that function for un-allocated, dense objects, provided your objects are numeric (more on this later).

So say we have the vector \code{x <- 1.0}.  This should be using 8 bytes to store that \code{1.0} as a double, right?  Well\dots
\begin{lstlisting}[language=rr]
> object.size(1.0)
48 bytes
\end{lstlisting}

So where is all that extra space coming from?  Simply put, \proglang{R} objects are more than just their data.  They contain a great deal of very useful metadata, which is where all the nice abstraction comes from.  Whenever you create a vector, \proglang{R} keeps track of, for example, its length.  If you do not appreciate this convenience, go learn \proglang{C} and then get back to me.  

For vectors, this overhead is 40 bytes, regardless of the type of data.  Matrices, unsurprisingly cost more, clocking in at 200 bytes overhead.  It is worth noting that this overhead does not scale; it is on a per-object basis.  So we don't need 40 bytes for each element of a vector when just 8 would do (in the case of double precision values).  We need 40 plus 8 per element:
\begin{lstlisting}[language=rr]
> # 2 elements
> 40+8*2
[1] 56
> object.size(rnorm(2))
56 bytes
> # 100.000 elements
> 40+1e5*8
[1] 800040
`> object.size(rnorm(1e5))
800040 bytes
\end{lstlisting}

The story is slightly more complicated for integer data (and a lot more complicated for strings; see the following section).  On my machine (and probably yours, but not necessarily), \code{int}s costs 4 bytes.  However, \proglang{R} does some aggressive allocation:
\begin{lstlisting}[language=rr]
> object.size(1L:3L)
56 bytes
> object.size(1L:4L)
56 bytes
\end{lstlisting}
Here we see \proglang{R} allocating more bytes than it needs for integer vectors sometimes, choosing to allocate in 16 byte chunks rather than 8 byte chunks.

The \pkg{memuse} package does not adjust for this overhead, because it honestly just doesn't matter.  This overhead is really not worth worrying about, and when you think about all the abstraction it buys you, it's a hell of a bargain.  If you have a million R objects stored, you're wasting less than one MiB ($1024^2$ bytes); so you would need a billion objects to use just about a GiB ($1024^3$ bytes) on overhead.  And if you're doing that kind of silly shit, my advice would be to learn how to properly use data structures.



\subsection{Strings}

String objects have been avoided up until this point because they are much more difficult to describe in general, unless they have a great deal of regularity imposed on them.  In \proglang{R}, strings by default are allocated to use 56 bytes (not counting overhead), unless they need more.  I'm not sure why this value was chosen, but 56 byte strings will allow for the storage of 7 chars (like \code{a} but not \code{aa}).  Each char costs 1 byte, so there's some fat overhead for the strings here, and almost certainly an additional byte held out for the null terminator.  So for example, recall that a vector allocates 40 bytes of overhead, so the vector string \code{letters} should use $56\times 26 + 40$ bytes.  We can easily verify that this is the case:
\begin{lstlisting}[language=rr]
> 56*26+40
[1] 1496
> object.size(letters)
1496 bytes
\end{lstlisting}

If you have a string with more than 7 chars, \proglang{R} will allocate extra space in 8-16 byte blocks.  After the initial 8 byte allocation (7 chars $+$ null terminator), if you need more you get an additional 8 bytes (in reality this is probably a contiguous 16 byte allocation; I have not bothered to check).  Beyond that, storage is allocate in 16 byte blocks for each string.  For example:
\begin{lstlisting}[language=rr]
>  object.size(c(paste(rep("a", 7), collapse=""), "a")) 
152 bytes
>  object.size(c(paste(rep("a", 7+1), collapse=""), "a")) 
160 bytes
>  object.size(c(paste(rep("a", 7+8+1), collapse=""), "a")) 
176 bytes
>  object.size(c(paste(rep("a", 7+8+16+1), collapse=""), "a")) 
192 bytes
\end{lstlisting}

If you have a vector of strings with them of varying lengths, the allocation of individual elements is handled on a case-by-case basis.  Consider the following:
\begin{lstlisting}[language=rr]
> object.size(c(paste(rep("a", 7+8+16+1), collapse=""), "a")) 
192 bytes
\end{lstlisting}

This object (the vector of 2 elements with first element ``aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'' and second element ``a'') is using 40 bytes for the vector, $56+8+16+16$ bytes for the first element, and 56 bytes for the second.

For all of these reasons, and given the fact that I almost never (ever) deal with character data, I have not bothered to make any attempt to extend, for example, \code{howmany()} or \code{howbig()}, to incorporate strings.  Deal with it, nerd.